{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "artificial-fence",
   "metadata": {},
   "source": [
    "Script to run baseline:\n",
    "\n",
    "```\n",
    "\n",
    "python train.py link_prediction with \\                                     \n",
    "dataset='FB15k-237' \\\n",
    "inductive=True \\\n",
    "model='bert-dkrl' \\\n",
    "rel_model='transe' \\\n",
    "loss_fn='margin' \\\n",
    "regularizer=1e-2 \\\n",
    "max_len=32 \\\n",
    "num_negatives=64 \\\n",
    "lr=1e-4 \\\n",
    "use_scheduler=False \\\n",
    "batch_size=64 \\\n",
    "emb_batch_size=512 \\\n",
    "eval_batch_size=128 \\\n",
    "max_epochs=5 \\\n",
    "checkpoint=None \\\n",
    "use_cached_text=False\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tough-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/suparnaghanvatkar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/suparnaghanvatkar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sacred.run import Run\n",
    "from logging import Logger\n",
    "from sacred import Experiment\n",
    "from sacred.observers import MongoObserver\n",
    "from transformers import BertTokenizer, get_linear_schedule_with_warmup\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from data import CATEGORY_IDS\n",
    "from data import GraphDataset, TextGraphDataset, GloVeTokenizer\n",
    "import models\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "arranged-washer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suparnaghanvatkar/anaconda3/envs/blp/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "OUT_PATH = 'output/'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ranking-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_link_prediction(model, triples_loader, text_dataset, entities,\n",
    "                         epoch, emb_batch_size,\n",
    "                         prefix='', max_num_batches=None,\n",
    "                         filtering_graph=None, new_entities=None,\n",
    "                         return_embeddings=False):\n",
    "    compute_filtered = filtering_graph is not None\n",
    "    mrr_by_position = torch.zeros(3, dtype=torch.float).to(device)\n",
    "    mrr_pos_counts = torch.zeros_like(mrr_by_position)\n",
    "\n",
    "    rel_categories = triples_loader.dataset.rel_categories.to(device)\n",
    "    mrr_by_category = torch.zeros([2, 4], dtype=torch.float).to(device)\n",
    "    mrr_cat_count = torch.zeros([1, 4], dtype=torch.float).to(device)\n",
    "\n",
    "    hit_positions = [1, 3, 10]\n",
    "    hits_at_k = {pos: 0.0 for pos in hit_positions}\n",
    "    mrr = 0.0\n",
    "    mrr_filt = 0.0\n",
    "    hits_at_k_filt = {pos: 0.0 for pos in hit_positions}\n",
    "\n",
    "    if device != torch.device('cpu'):\n",
    "        model = model.module\n",
    "\n",
    "    if isinstance(model, models.InductiveLinkPrediction):\n",
    "        num_entities = entities.shape[0]\n",
    "        if compute_filtered:\n",
    "            max_ent_id = max(filtering_graph.nodes)\n",
    "        else:\n",
    "            max_ent_id = entities.max()\n",
    "        ent2idx = utils.make_ent2idx(entities, max_ent_id)\n",
    "    else:\n",
    "        # Transductive models have a lookup table of embeddings\n",
    "        num_entities = model.ent_emb.num_embeddings\n",
    "        ent2idx = torch.arange(num_entities)\n",
    "        entities = ent2idx\n",
    "\n",
    "    # Create embedding lookup table for evaluation\n",
    "    ent_emb = torch.zeros((num_entities, model.dim), dtype=torch.float,\n",
    "                          device=device)\n",
    "    idx = 0\n",
    "    num_iters = np.ceil(num_entities / emb_batch_size)\n",
    "    iters_count = 0\n",
    "    while idx < num_entities:\n",
    "        # Get a batch of entity IDs and encode them\n",
    "        batch_ents = entities[idx:idx + emb_batch_size]\n",
    "\n",
    "        if isinstance(model, models.InductiveLinkPrediction):\n",
    "            # Encode with entity descriptions\n",
    "            data = text_dataset.get_entity_description(batch_ents)\n",
    "            text_tok, text_mask, text_len = data\n",
    "            batch_emb = model(text_tok.unsqueeze(1).to(device),\n",
    "                              text_mask.unsqueeze(1).to(device))\n",
    "        else:\n",
    "            # Encode from lookup table\n",
    "            batch_emb = model(batch_ents)\n",
    "\n",
    "        ent_emb[idx:idx + batch_ents.shape[0]] = batch_emb\n",
    "\n",
    "        iters_count += 1\n",
    "        if iters_count % np.ceil(0.2 * num_iters) == 0:\n",
    "            print(f'[{idx + batch_ents.shape[0]:,}/{num_entities:,}]')\n",
    "\n",
    "        idx += emb_batch_size\n",
    "\n",
    "    ent_emb = ent_emb.unsqueeze(0)\n",
    "\n",
    "    batch_count = 0\n",
    "    print('Computing metrics on set of triples')\n",
    "    total = len(triples_loader) if max_num_batches is None else max_num_batches\n",
    "    for i, triples in enumerate(triples_loader):\n",
    "        if max_num_batches is not None and i == max_num_batches:\n",
    "            break\n",
    "\n",
    "        heads, tails, rels = torch.chunk(triples, chunks=3, dim=1)\n",
    "        # Map entity IDs to positions in ent_emb\n",
    "        heads = ent2idx[heads].to(device)\n",
    "        tails = ent2idx[tails].to(device)\n",
    "\n",
    "        assert heads.min() >= 0\n",
    "        assert tails.min() >= 0\n",
    "\n",
    "        # Embed triple\n",
    "        head_embs = ent_emb.squeeze()[heads]\n",
    "        tail_embs = ent_emb.squeeze()[tails]\n",
    "        rel_embs = model.rel_emb(rels.to(device))\n",
    "\n",
    "        # Score all possible heads and tails\n",
    "        heads_predictions = model.score_fn(ent_emb, tail_embs, rel_embs)\n",
    "        tails_predictions = model.score_fn(head_embs, ent_emb, rel_embs)\n",
    "\n",
    "        pred_ents = torch.cat((heads_predictions, tails_predictions))\n",
    "        true_ents = torch.cat((heads, tails))\n",
    "\n",
    "        hits = utils.hit_at_k(pred_ents, true_ents, hit_positions)\n",
    "        for j, h in enumerate(hits):\n",
    "            hits_at_k[hit_positions[j]] += h\n",
    "        mrr += utils.mrr(pred_ents, true_ents).mean().item()\n",
    "\n",
    "        if compute_filtered:\n",
    "            filters = utils.get_triple_filters(triples, filtering_graph,\n",
    "                                               num_entities, ent2idx)\n",
    "            heads_filter, tails_filter = filters\n",
    "            # Filter entities by assigning them the lowest score in the batch\n",
    "            filter_mask = torch.cat((heads_filter, tails_filter)).to(device)\n",
    "            pred_ents[filter_mask] = pred_ents.min() - 1.0\n",
    "            hits_filt = utils.hit_at_k(pred_ents, true_ents, hit_positions)\n",
    "            for j, h in enumerate(hits_filt):\n",
    "                hits_at_k_filt[hit_positions[j]] += h\n",
    "            mrr_filt_per_triple = utils.mrr(pred_ents, true_ents)\n",
    "            mrr_filt += mrr_filt_per_triple.mean().item()\n",
    "\n",
    "            if new_entities is not None:\n",
    "                by_position = utils.split_by_new_position(triples,\n",
    "                                                          mrr_filt_per_triple,\n",
    "                                                          new_entities)\n",
    "                batch_mrr_by_position, batch_mrr_pos_counts = by_position\n",
    "                mrr_by_position += batch_mrr_by_position\n",
    "                mrr_pos_counts += batch_mrr_pos_counts\n",
    "\n",
    "            if triples_loader.dataset.has_rel_categories:\n",
    "                by_category = utils.split_by_category(triples,\n",
    "                                                      mrr_filt_per_triple,\n",
    "                                                      rel_categories)\n",
    "                batch_mrr_by_cat, batch_mrr_cat_count = by_category\n",
    "                mrr_by_category += batch_mrr_by_cat\n",
    "                mrr_cat_count += batch_mrr_cat_count\n",
    "\n",
    "        batch_count += 1\n",
    "        if (i + 1) % int(0.2 * total) == 0:\n",
    "            print(f'[{i + 1:,}/{total:,}]')\n",
    "\n",
    "    for hits_dict in (hits_at_k, hits_at_k_filt):\n",
    "        for k in hits_dict:\n",
    "            hits_dict[k] /= batch_count\n",
    "\n",
    "    mrr = mrr / batch_count\n",
    "    mrr_filt = mrr_filt / batch_count\n",
    "\n",
    "    log_str = f'{prefix} mrr: {mrr:.4f}  '\n",
    "    print(f'{prefix}_mrr', mrr, epoch)\n",
    "    for k, value in hits_at_k.items():\n",
    "        log_str += f'hits@{k}: {value:.4f}  '\n",
    "        print(f'{prefix}_hits@{k}', value, epoch)\n",
    "\n",
    "    if compute_filtered:\n",
    "        log_str += f'mrr_filt: {mrr_filt:.4f}  '\n",
    "        print(f'{prefix}_mrr_filt', mrr_filt, epoch)\n",
    "        for k, value in hits_at_k_filt.items():\n",
    "            log_str += f'hits@{k}_filt: {value:.4f}  '\n",
    "            print(f'{prefix}_hits@{k}_filt', value, epoch)\n",
    "\n",
    "    print(log_str)\n",
    "\n",
    "    if new_entities is not None and compute_filtered:\n",
    "        mrr_pos_counts[mrr_pos_counts < 1.0] = 1.0\n",
    "        mrr_by_position = mrr_by_position / mrr_pos_counts\n",
    "        log_str = ''\n",
    "        for i, t in enumerate((f'{prefix}_mrr_filt_both_new',\n",
    "                               f'{prefix}_mrr_filt_head_new',\n",
    "                               f'{prefix}_mrr_filt_tail_new')):\n",
    "            value = mrr_by_position[i].item()\n",
    "            log_str += f'{t}: {value:.4f}  '\n",
    "            print(t, value, epoch)\n",
    "        print(log_str)\n",
    "\n",
    "    if compute_filtered and triples_loader.dataset.has_rel_categories:\n",
    "        mrr_cat_count[mrr_cat_count < 1.0] = 1.0\n",
    "        mrr_by_category = mrr_by_category / mrr_cat_count\n",
    "\n",
    "        for i, case in enumerate(['pred_head', 'pred_tail']):\n",
    "            log_str = f'{case} '\n",
    "            for cat, cat_id in CATEGORY_IDS.items():\n",
    "                log_str += f'{cat}_mrr: {mrr_by_category[i, cat_id]:.4f}  '\n",
    "            print(log_str)\n",
    "\n",
    "    if return_embeddings:\n",
    "        out = (mrr, ent_emb)\n",
    "    else:\n",
    "        out = (mrr, None)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intermediate-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction(dataset, inductive, dim, model, rel_model, loss_fn,\n",
    "                    encoder_name, regularizer, max_len, num_negatives, lr,\n",
    "                    use_scheduler, batch_size, emb_batch_size, eval_batch_size,\n",
    "                    max_epochs, checkpoint, use_cached_text):\n",
    "    drop_stopwords = model in {'bert-bow', 'bert-dkrl',\n",
    "                               'glove-bow', 'glove-dkrl'}\n",
    "\n",
    "    prefix = 'ind-' if inductive and model != 'transductive' else ''\n",
    "    triples_file = f'data/{dataset}/{prefix}train.tsv'\n",
    "\n",
    "    if device != torch.device('cpu'):\n",
    "        num_devices = torch.cuda.device_count()\n",
    "        if batch_size % num_devices != 0:\n",
    "            raise ValueError(f'Batch size ({batch_size}) must be a multiple of'\n",
    "                             f' the number of CUDA devices ({num_devices})')\n",
    "        print(f'CUDA devices used: {num_devices}')\n",
    "    else:\n",
    "        num_devices = 1\n",
    "        print('Training on CPU')\n",
    "\n",
    "    if model == 'transductive':\n",
    "        train_data = GraphDataset(triples_file, num_negatives,\n",
    "                                  write_maps_file=True,\n",
    "                                  num_devices=num_devices)\n",
    "    else:\n",
    "        if model.startswith('bert') or model == 'blp':\n",
    "            tokenizer = BertTokenizer.from_pretrained(encoder_name)\n",
    "        else:\n",
    "            tokenizer = GloVeTokenizer('data/glove/glove.6B.300d-maps.pt')\n",
    "\n",
    "        train_data = TextGraphDataset(triples_file, num_negatives,\n",
    "                                      max_len, tokenizer, drop_stopwords,\n",
    "                                      write_maps_file=True,\n",
    "                                      use_cached_text=use_cached_text,\n",
    "                                      num_devices=num_devices)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size, shuffle=True,\n",
    "                              collate_fn=train_data.collate_fn,\n",
    "                              num_workers=0, drop_last=True)\n",
    "\n",
    "    train_eval_loader = DataLoader(train_data, eval_batch_size)\n",
    "\n",
    "    valid_data = GraphDataset(f'data/{dataset}/{prefix}dev.tsv')\n",
    "    valid_loader = DataLoader(valid_data, eval_batch_size)\n",
    "\n",
    "    test_data = GraphDataset(f'data/{dataset}/{prefix}test.tsv')\n",
    "    test_loader = DataLoader(test_data, eval_batch_size)\n",
    "\n",
    "    # Build graph with all triples to compute filtered metrics\n",
    "    if dataset != 'Wikidata5M':\n",
    "        graph = nx.MultiDiGraph()\n",
    "        all_triples = torch.cat((train_data.triples,\n",
    "                                 valid_data.triples,\n",
    "                                 test_data.triples))\n",
    "        graph.add_weighted_edges_from(all_triples.tolist())\n",
    "\n",
    "        train_ent = set(train_data.entities.tolist())\n",
    "        train_val_ent = set(valid_data.entities.tolist()).union(train_ent)\n",
    "        train_val_test_ent = set(test_data.entities.tolist()).union(train_val_ent)\n",
    "        val_new_ents = train_val_ent.difference(train_ent)\n",
    "        test_new_ents = train_val_test_ent.difference(train_val_ent)\n",
    "    else:\n",
    "        graph = None\n",
    "\n",
    "        train_ent = set(train_data.entities.tolist())\n",
    "        train_val_ent = set(valid_data.entities.tolist())\n",
    "        train_val_test_ent = set(test_data.entities.tolist())\n",
    "        val_new_ents = test_new_ents = None\n",
    "\n",
    "    print('num_train_entities', len(train_ent))\n",
    "\n",
    "    train_ent = torch.tensor(list(train_ent))\n",
    "    train_val_ent = torch.tensor(list(train_val_ent))\n",
    "    train_val_test_ent = torch.tensor(list(train_val_test_ent))\n",
    "\n",
    "    model = utils.get_model(model, dim, rel_model, loss_fn,\n",
    "                            len(train_val_test_ent), train_data.num_rels,\n",
    "                            encoder_name, regularizer)\n",
    "    if checkpoint is not None:\n",
    "        model.load_state_dict(torch.load(checkpoint, map_location='cpu'))\n",
    "\n",
    "    if device != torch.device('cpu'):\n",
    "        model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    total_steps = len(train_loader) * max_epochs\n",
    "    if use_scheduler:\n",
    "        warmup = int(0.2 * total_steps)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=warmup,\n",
    "                                                    num_training_steps=total_steps)\n",
    "    best_valid_mrr = 0.0\n",
    "    checkpoint_file = osp.join(OUT_PATH, f'model-base.pt')\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        train_loss = 0\n",
    "        for step, data in enumerate(train_loader):\n",
    "            loss = model(*data).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if use_scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if step % int(0.05 * len(train_loader)) == 0:\n",
    "                print(f'Epoch {epoch}/{max_epochs} '\n",
    "                          f'[{step}/{len(train_loader)}]: {loss.item():.6f}')\n",
    "                print('batch_loss', loss.item())\n",
    "\n",
    "        print('train_loss', train_loss / len(train_loader), epoch)\n",
    "\n",
    "        if dataset != 'Wikidata5M':\n",
    "            print('Evaluating on sample of training set')\n",
    "            eval_link_prediction(model, train_eval_loader, train_data, train_ent,\n",
    "                                 epoch, emb_batch_size, prefix='train',\n",
    "                                 max_num_batches=len(valid_loader))\n",
    "\n",
    "        print('Evaluating on validation set')\n",
    "        val_mrr, _ = eval_link_prediction(model, valid_loader, train_data,\n",
    "                                          train_val_ent, epoch,\n",
    "                                          emb_batch_size, prefix='valid')\n",
    "\n",
    "        # Keep checkpoint of best performing model (based on raw MRR)\n",
    "        if val_mrr > best_valid_mrr:\n",
    "            best_valid_mrr = val_mrr\n",
    "            torch.save(model.state_dict(), checkpoint_file)\n",
    "\n",
    "    # Evaluate with best performing checkpoint\n",
    "    if max_epochs > 0:\n",
    "        model.load_state_dict(torch.load(checkpoint_file))\n",
    "\n",
    "    if dataset == 'Wikidata5M':\n",
    "        graph = nx.MultiDiGraph()\n",
    "        graph.add_weighted_edges_from(valid_data.triples.tolist())\n",
    "\n",
    "    print('Evaluating on validation set (with filtering)')\n",
    "    eval_link_prediction(model, valid_loader, train_data, train_val_ent,\n",
    "                         max_epochs + 1, emb_batch_size, prefix='valid',\n",
    "                         filtering_graph=graph,\n",
    "                         new_entities=val_new_ents)\n",
    "\n",
    "    if dataset == 'Wikidata5M':\n",
    "        graph = nx.MultiDiGraph()\n",
    "        graph.add_weighted_edges_from(test_data.triples.tolist())\n",
    "\n",
    "    print('Evaluating on test set')\n",
    "    _, ent_emb = eval_link_prediction(model, test_loader, train_data,\n",
    "                                      train_val_test_ent, max_epochs + 1,\n",
    "                                      emb_batch_size, prefix='test',\n",
    "                                      filtering_graph=graph,\n",
    "                                      new_entities=test_new_ents,\n",
    "                                      return_embeddings=True)\n",
    "\n",
    "    # Save final entity embeddings obtained with trained encoder\n",
    "    torch.save(ent_emb, osp.join(OUT_PATH, f'ent_emb-base.pt'))\n",
    "    torch.save(train_val_test_ent, osp.join(OUT_PATH, f'ents-base.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading entity descriptions:   0%|          | 0/14541 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Reading entity descriptions: 100%|██████████| 14541/14541 [00:32<00:00, 445.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_entities 11633\n",
      "Epoch 1/1 [0/3360]: 0.999054\n",
      "batch_loss 0.9990540146827698\n",
      "Epoch 1/1 [168/3360]: 0.227189\n",
      "batch_loss 0.22718869149684906\n",
      "Epoch 1/1 [336/3360]: 0.134670\n",
      "batch_loss 0.13467003405094147\n",
      "Epoch 1/1 [504/3360]: 0.139251\n",
      "batch_loss 0.1392514556646347\n",
      "Epoch 1/1 [672/3360]: 0.122351\n",
      "batch_loss 0.12235123664140701\n",
      "Epoch 1/1 [840/3360]: 0.091599\n",
      "batch_loss 0.09159908443689346\n",
      "Epoch 1/1 [1008/3360]: 0.136284\n",
      "batch_loss 0.13628406822681427\n",
      "Epoch 1/1 [1176/3360]: 0.127775\n",
      "batch_loss 0.1277754306793213\n",
      "Epoch 1/1 [1344/3360]: 0.081928\n",
      "batch_loss 0.08192778378725052\n",
      "Epoch 1/1 [1512/3360]: 0.064411\n",
      "batch_loss 0.06441084295511246\n",
      "Epoch 1/1 [1680/3360]: 0.084334\n",
      "batch_loss 0.08433400094509125\n",
      "Epoch 1/1 [1848/3360]: 0.076564\n",
      "batch_loss 0.07656361162662506\n",
      "Epoch 1/1 [2016/3360]: 0.058254\n",
      "batch_loss 0.05825385823845863\n",
      "Epoch 1/1 [2184/3360]: 0.072447\n",
      "batch_loss 0.07244671881198883\n",
      "Epoch 1/1 [2352/3360]: 0.057176\n",
      "batch_loss 0.05717641860246658\n",
      "Epoch 1/1 [2520/3360]: 0.078805\n",
      "batch_loss 0.07880472391843796\n",
      "Epoch 1/1 [2688/3360]: 0.068816\n",
      "batch_loss 0.06881649047136307\n",
      "Epoch 1/1 [2856/3360]: 0.060517\n",
      "batch_loss 0.06051701307296753\n",
      "Epoch 1/1 [3024/3360]: 0.082890\n",
      "batch_loss 0.08288984000682831\n",
      "Epoch 1/1 [3192/3360]: 0.064573\n",
      "batch_loss 0.06457331776618958\n",
      "train_loss 0.11128741116706459 1\n",
      "Evaluating on sample of training set\n",
      "[2,560/11,633]\n",
      "[5,120/11,633]\n",
      "[7,680/11,633]\n",
      "[10,240/11,633]\n",
      "Computing metrics on set of triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suparnaghanvatkar/NUS/CS6216/project/utils.py:123: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  rankings = (indices == ground_truth_idx).nonzero()[:, 1].float() + 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66/330]\n",
      "[132/330]\n"
     ]
    }
   ],
   "source": [
    "link_prediction(dataset='FB15k-237', inductive=True, dim=128, model='bert-dkrl', rel_model='transe', loss_fn='margin', \\\n",
    "                    encoder_name='bert-base-cased', regularizer=1e-2, max_len=32, num_negatives=64, lr=1e-4, use_scheduler=False, batch_size=64, emb_batch_size=512, eval_batch_size=128,\\\n",
    "                    max_epochs=1, checkpoint=None, use_cached_text=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
